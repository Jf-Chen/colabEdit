在colab中运行时，先拷贝colabEdit/GLoFA到sample_data

再从google drive下载mini_imagenet.tar



程序流程

~~~python
===== task arguments =====
data_name = mini_imagenet
network_name = resnet
model_name = glofa
N = 5
K = 1
Q = 15
===== experiment environment arguments =====
devices = [0]
flag_debug = False
n_workers = 8
===== optimizer arguments =====
lr_network = 0.000100
lr = 0.010000
point = (20, 30, 40)
gamma = 0.200000
wd = 0.000500
mo = 0.900000
===== training procedure arguments =====
n_training_episodes = 10000
n_validating_episodes = 200
n_testing_episodes = 10000
episode_gap = 200
===== model arguments =====
tau = 1.000000
delta = 1.000000
~~~

dataloader.generate_data_loader(data_path, flag_mode, n_episodes, N, S)

~~~python
# Train.py
一个episode中取80张图，80个标签
logits=model.forward(images) # glofa.forward()
~~~

glofa.py
~~~python
# glofa.py 
N=5,K=1,Q=15# 
resnet.encoder()
support_embedding # 5
query_embedding #75
set_function(640,640,level='task')

~~~



mask_task = self.f_task(support_embeddings, level='task').unsqueeze(0)

mask_class = self.f_class(support_embeddings, level='class').unsqueeze(0)



set_function.py就是MLP，可以从原文的公式11看出来

~~~python
# set_function level='task'
(psi): Sequential(
     (0): Linear(in_features=640, out_features=1280, bias=True)
     (1): ReLU()
     (2): Linear(in_features=1280, out_features=1280, bias=True)
     (3): ReLU()
     )
~~~

 $\phi(x)$
psi_output = self.psi(support_embeddings) 

 $[MLP(\phi(x));\phi(x)]$
rho_input = torch.cat([psi_output, support_embeddings], dim=1)

 $(\sum \limits_{x \in A}[MLP(\phi(x));\phi(x)])$
rho_input = torch.sum(rho_input, dim=0, keepdim=True)

$MLP(\sum \limits_{x \in A}[MLP(\phi(x));\phi(x)])$
rho_output = torch.nn.functional.relu6(self.rho(rho_input)) / 6 * self.args.delta 