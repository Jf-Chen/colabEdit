{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DN4测试.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOO3iqxdD3k4wSq2kAUxZCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jf-Chen/colabEdit/blob/main/DN4%E6%B5%8B%E8%AF%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP1IxXrZHCVd",
        "outputId": "531b55dd-be0f-42e3-be84-c2e6029b0ab1"
      },
      "source": [
        "# 准备工作\n",
        "! pwd\n",
        "! mkdir /content/run\n",
        "% cd /content/run\n",
        "\n",
        "# 下载代码\n",
        "! git clone https://github.com/Jf-Chen/colabEdit.git\n",
        "% cd /content/run/colabEdit/DN4\n",
        "\n",
        "# 下载mini-imagenet.zip\n",
        "\n",
        "! gdown --id 1HkgrkAwukzEZA0TpO7010PkAOREb2Nuk\n",
        "! unzip -uq \"/content/run/colabEdit/DN4/mini-imagenet.zip\" -d \"./dataset/miniImageNet\"\n",
        "! pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/run\n",
            "Cloning into 'colabEdit'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (123/123), done.\u001b[K\n",
            "remote: Total 166 (delta 39), reused 149 (delta 31), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (166/166), 22.66 MiB | 8.52 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "/content/run/colabEdit/DN4\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HkgrkAwukzEZA0TpO7010PkAOREb2Nuk\n",
            "To: /content/run/colabEdit/DN4/mini-imagenet.zip\n",
            "3.07GB [00:24, 124MB/s]\n",
            "/content/run/colabEdit/DN4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROAerKxzHxgk",
        "outputId": "92f2326c-7bb9-4ff0-b69f-f47e4be601ec"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import grad\n",
        "import time\n",
        "from torch import autograd\n",
        "from PIL import ImageFile\n",
        "import pdb\n",
        "import sys\n",
        "sys.dont_write_bytecode = True\n",
        "\n",
        "# ============================ Data & Networks =====================================\n",
        "from dataset.datasets_csv import Imagefolder_csv\n",
        "import models.network as DN4Net\n",
        "# ==================================================================================\n",
        "\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
        "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--dataset_dir', default='./dataset/miniImageNet', help='./miniImageNet')\n",
        "parser.add_argument('--data_name', default='miniImageNet', help='miniImageNet|StanfordDog|StanfordCar|CubBird')\n",
        "parser.add_argument('--mode', default='train', help='train|val|test')\n",
        "parser.add_argument('--outf', default='./results/DN4')\n",
        "parser.add_argument('--resume', default='', type=str, help='path to the lastest checkpoint (default: none)')\n",
        "parser.add_argument('--basemodel', default='Conv64F', help='Conv64F|ResNet256F')\n",
        "parser.add_argument('--workers', type=int, default=8)\n",
        "#  Few-shot parameters  #\n",
        "parser.add_argument('--imageSize', type=int, default=84)\n",
        "parser.add_argument('--episodeSize', type=int, default=1, help='the mini-batch size of training')\n",
        "parser.add_argument('--testepisodeSize', type=int, default=1, help='one episode is taken as a mini-batch')\n",
        "parser.add_argument('--epochs', type=int, default=30, help='the total number of training epoch')\n",
        "parser.add_argument('--episode_train_num', type=int, default=10000, help='the total number of training episodes')\n",
        "parser.add_argument('--episode_val_num', type=int, default=1000, help='the total number of evaluation episodes')\n",
        "parser.add_argument('--episode_test_num', type=int, default=1000, help='the total number of testing episodes')\n",
        "parser.add_argument('--way_num', type=int, default=5, help='the number of way/class')\n",
        "parser.add_argument('--shot_num', type=int, default=5, help='the number of shot')\n",
        "parser.add_argument('--query_num', type=int, default=10, help='the number of queries')\n",
        "parser.add_argument('--neighbor_k', type=int, default=3, help='the number of k-nearest neighbors')\n",
        "parser.add_argument('--lr', type=float, default=0.005, help='learning rate, default=0.005')\n",
        "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
        "parser.add_argument('--cuda', action='store_true', default=True, help='enables cuda')\n",
        "# action='store_true',触发opt.cuda时，cuda是true，不触发opt.cuda时，cuda是false\n",
        "parser.add_argument('--ngpu', type=int, default=1, help='the number of gpus')\n",
        "parser.add_argument('--nc', type=int, default=3, help='input image channels')\n",
        "parser.add_argument('--clamp_lower', type=float, default=-0.01)\n",
        "parser.add_argument('--clamp_upper', type=float, default=0.01)\n",
        "parser.add_argument('--print_freq', '-p', default=100, type=int, metavar='N', help='print frequency (default: 100)')\n",
        "opt,unknown = parser.parse_known_args()\n",
        "opt.cuda = True\n",
        "cudnn.benchmark = True\n",
        "\n",
        "# ======================================= Define functions =============================================\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch_num):\n",
        "\t\"\"\"Sets the learning rate to the initial LR decayed by 0.05 every 10 epochs\"\"\"\n",
        "\tlr = opt.lr * (0.05 ** (epoch_num // 10))\n",
        "\tfor param_group in optimizer.param_groups:\n",
        "\t\tparam_group['lr'] = lr\n",
        "\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch_index, F_txt):\n",
        "\tbatch_time = AverageMeter()\n",
        "\tdata_time = AverageMeter()\n",
        "\tlosses = AverageMeter()\n",
        "\ttop1 = AverageMeter()\n",
        "\n",
        "\n",
        "\tend = time.time()\n",
        "\tfor episode_index, (query_images, query_targets, support_images, support_targets) in enumerate(train_loader):\n",
        "\n",
        "\t\t# Measure data loading time\n",
        "\t\tdata_time.update(time.time() - end)\n",
        "\n",
        "\t\t# Convert query and support images\n",
        "\t\tquery_images = torch.cat(query_images, 0)\n",
        "\t\tinput_var1 = query_images.cuda()\n",
        "\n",
        "\t\tinput_var2 = []\n",
        "\t\tfor i in range(len(support_images)):\n",
        "\t\t\ttemp_support = support_images[i]\n",
        "\t\t\ttemp_support = torch.cat(temp_support, 0)\n",
        "\t\t\ttemp_support = temp_support.cuda()\n",
        "\t\t\tinput_var2.append(temp_support)\n",
        "\n",
        "\t\t# Deal with the targets\n",
        "\t\ttarget = torch.cat(query_targets, 0)\n",
        "\t\ttarget = target.cuda()\n",
        "\n",
        "\t\t# Calculate the output\n",
        "\t\toutput = model(input_var1, input_var2)\n",
        "\t\tloss = criterion(output, target)\n",
        "\n",
        "\t\t# Compute gradients and do SGD step\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\n",
        "\t  \n",
        "\t\t# Measure accuracy and record loss\n",
        "\t\tprec1, _ = accuracy(output, target, topk=(1,3))\n",
        "\t\tlosses.update(loss.item(), query_images.size(0))\n",
        "\t\ttop1.update(prec1[0], query_images.size(0))\n",
        "\n",
        "\n",
        "\t\t# Measure elapsed time\n",
        "\t\tbatch_time.update(time.time() - end)\n",
        "\t\tend = time.time()\n",
        "\n",
        "\n",
        "\t\t#============== print the intermediate results ==============#\n",
        "\t\tif episode_index % opt.print_freq == 0 and episode_index != 0:\n",
        "\n",
        "\t\t\tprint('Eposide-({0}): [{1}/{2}]\\t'\n",
        "\t\t\t\t'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "\t\t\t\t'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "\t\t\t\t'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
        "\t\t\t\t'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "\t\t\t\t\tepoch_index, episode_index, len(train_loader), batch_time=batch_time, data_time=data_time, loss=losses, top1=top1))\n",
        "\n",
        "\t\t\tprint('Eposide-({0}): [{1}/{2}]\\t'\n",
        "\t\t\t\t'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "\t\t\t\t'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "\t\t\t\t'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
        "\t\t\t\t'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "\t\t\t\t\tepoch_index, episode_index, len(train_loader), batch_time=batch_time, data_time=data_time, loss=losses, top1=top1), file=F_txt)\n",
        "\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion, epoch_index, best_prec1, F_txt):\n",
        "\tbatch_time = AverageMeter()\n",
        "\tlosses = AverageMeter()\n",
        "\ttop1 = AverageMeter()\n",
        "\n",
        "\n",
        "\t# switch to evaluate mode\n",
        "\tmodel.eval()\n",
        "\taccuracies = []\n",
        "\n",
        "\n",
        "\tend = time.time()\n",
        "\tfor episode_index, (query_images, query_targets, support_images, support_targets) in enumerate(val_loader):\n",
        "\n",
        "\t\t# Convert query and support images\n",
        "\t\tquery_images = torch.cat(query_images, 0)\n",
        "\t\tinput_var1 = query_images.cuda()\n",
        "\n",
        "\n",
        "\t\tinput_var2 = []\n",
        "\t\tfor i in range(len(support_images)):\n",
        "\t\t\ttemp_support = support_images[i]\n",
        "\t\t\ttemp_support = torch.cat(temp_support, 0)\n",
        "\t\t\ttemp_support = temp_support.cuda()\n",
        "\t\t\tinput_var2.append(temp_support)\n",
        "\n",
        "\n",
        "\t\t# Deal with the targets\n",
        "\t\ttarget = torch.cat(query_targets, 0)\n",
        "\t\ttarget = target.cuda()\n",
        "\n",
        "\t\t# Calculate the output \n",
        "\t\toutput = model(input_var1, input_var2)\n",
        "\t\tloss = criterion(output, target)\n",
        "\n",
        "\n",
        "\t\t# measure accuracy and record loss\n",
        "\t\tprec1, _ = accuracy(output, target, topk=(1, 3))\n",
        "\t\tlosses.update(loss.item(), query_images.size(0))\n",
        "\t\ttop1.update(prec1[0], query_images.size(0))\n",
        "\t\taccuracies.append(prec1)\n",
        "\n",
        "\n",
        "\t\t# measure elapsed time\n",
        "\t\tbatch_time.update(time.time() - end)\n",
        "\t\tend = time.time()\n",
        "\n",
        "\n",
        "\t\t#============== print the intermediate results ==============#\n",
        "\t\tif episode_index % opt.print_freq == 0 and episode_index != 0:\n",
        "\n",
        "\t\t\tprint('Test-({0}): [{1}/{2}]\\t'\n",
        "\t\t\t\t'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "\t\t\t\t'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
        "\t\t\t\t'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "\t\t\t\t\tepoch_index, episode_index, len(val_loader), batch_time=batch_time, loss=losses, top1=top1))\n",
        "\n",
        "\t\t\tprint('Test-({0}): [{1}/{2}]\\t'\n",
        "\t\t\t\t'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "\t\t\t\t'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
        "\t\t\t\t'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
        "\t\t\t\t\tepoch_index, episode_index, len(val_loader), batch_time=batch_time, loss=losses, top1=top1), file=F_txt)\n",
        "\n",
        "\t\t\n",
        "\tprint(' * Prec@1 {top1.avg:.3f} Best_prec1 {best_prec1:.3f}'.format(top1=top1, best_prec1=best_prec1))\n",
        "\tprint(' * Prec@1 {top1.avg:.3f} Best_prec1 {best_prec1:.3f}'.format(top1=top1, best_prec1=best_prec1), file=F_txt)\n",
        "\n",
        "\treturn top1.avg, accuracies\n",
        "\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
        "\ttorch.save(state, filename)\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "\t\"\"\"Computes and stores the average and current value\"\"\"\n",
        "\tdef __init__(self):\n",
        "\t\tself.reset()\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\tself.val = 0\n",
        "\t\tself.avg = 0\n",
        "\t\tself.sum = 0\n",
        "\t\tself.count = 0\n",
        "\n",
        "\tdef update(self, val, n=1):\n",
        "\t\tself.val = val\n",
        "\t\tself.sum += val * n\n",
        "\t\tself.count += n\n",
        "\t\tself.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "\t\"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "\twith torch.no_grad():\n",
        "\t\tmaxk = max(topk)\n",
        "\t\tbatch_size = target.size(0)\n",
        "\n",
        "\t\t_, pred = output.topk(maxk, 1, True, True)\n",
        "\t\tpred = pred.t()\n",
        "\t\tcorrect = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "\t\tres = []\n",
        "\t\tfor k in topk:\n",
        "\t\t\tcorrect_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "\t\t\tres.append(correct_k.mul_(100.0 / batch_size))\n",
        "\t\treturn res\n",
        "\n",
        "\n",
        "# ======================================== Settings of path ============================================\n",
        "# saving path\n",
        "opt.outf = opt.outf+'_'+opt.data_name+'_'+str(opt.basemodel)+'_'+str(opt.way_num)+'Way_'+str(opt.shot_num)+'Shot'+'_K'+str(opt.neighbor_k)\n",
        "\n",
        "if not os.path.exists(opt.outf):\n",
        "\tos.makedirs(opt.outf)\n",
        "\n",
        "if torch.cuda.is_available() and not opt.cuda:\n",
        "\tprint(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "# save the opt and results to a txt file\n",
        "txt_save_path = os.path.join(opt.outf, 'opt_resutls.txt')\n",
        "F_txt = open(txt_save_path, 'a+')\n",
        "print(opt)\n",
        "print(opt, file=F_txt)\n",
        "\n",
        "# ========================================== Model Config ===============================================\n",
        "ngpu = int(opt.ngpu)\n",
        "global best_prec1, epoch_index\n",
        "best_prec1 = 0\n",
        "epoch_index = 0\n",
        "\n",
        "# model = DN4Net.define_DN4Net(which_model=Conv64F, num_classes=5, neighbor_k=3, norm='batch', \n",
        "model = DN4Net.define_DN4Net(which_model=opt.basemodel, num_classes=opt.way_num, neighbor_k=opt.neighbor_k, norm='batch', \n",
        "\tinit_type='normal', use_gpu=opt.cuda)\n",
        "\n",
        "# define loss function (criterion) and optimizer\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=opt.lr, betas=(opt.beta1, 0.9))\n",
        "\n",
        "\n",
        "# optionally resume from a checkpoint\n",
        "if opt.resume:\n",
        "\tif os.path.isfile(opt.resume):\n",
        "\t\tprint(\"=> loading checkpoint '{}'\".format(opt.resume))\n",
        "\t\tcheckpoint = torch.load(opt.resume)\n",
        "\t\tepoch_index = checkpoint['epoch_index']\n",
        "\t\tbest_prec1 = checkpoint['best_prec1']\n",
        "\t\tmodel.load_state_dict(checkpoint['state_dict'])\n",
        "\t\toptimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\t\tprint(\"=> loaded checkpoint '{}' (epoch {})\".format(opt.resume, checkpoint['epoch_index']))\n",
        "\t\tprint(\"=> loaded checkpoint '{}' (epoch {})\".format(opt.resume, checkpoint['epoch_index']), file=F_txt)\n",
        "\telse:\n",
        "\t\tprint(\"=> no checkpoint found at '{}'\".format(opt.resume))\n",
        "\t\tprint(\"=> no checkpoint found at '{}'\".format(opt.resume), file=F_txt)\n",
        "\n",
        "if opt.ngpu > 1:\n",
        "\tmodel = nn.DataParallel(model, range(opt.ngpu))\n",
        "\n",
        "# print the architecture of the network\n",
        "print(model) \n",
        "print(model, file=F_txt) \n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(basemodel='Conv64F', beta1=0.5, clamp_lower=-0.01, clamp_upper=0.01, cuda=True, data_name='miniImageNet', dataset_dir='./dataset/miniImageNet', episodeSize=1, episode_test_num=1000, episode_train_num=10000, episode_val_num=1000, epochs=30, imageSize=84, lr=0.005, mode='train', nc=3, neighbor_k=3, ngpu=1, outf='./results/DN4_miniImageNet_Conv64F_5Way_5Shot_K3', print_freq=100, query_num=10, resume='', shot_num=5, testepisodeSize=1, way_num=5, workers=8)\n",
            "initialization method [normal]\n",
            "FourLayer_64F(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (imgtoclass): ImgtoClass_Metric()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwR5ya1yIzbf",
        "outputId": "4df2f618-4791-47ff-efb4-c3473cbc9afe"
      },
      "source": [
        "# 选择一个循环\n",
        "\n",
        "# ======================================= Folder of Datasets =======================================\n",
        "# image transform & normalization\n",
        "ImgTransform = transforms.Compose([\n",
        "    transforms.Resize((opt.imageSize, opt.imageSize)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "  # opt.imageSize=84,episode_train_num=10000,way=5,shot=1,query_num=15\n",
        "trainset = Imagefolder_csv(\n",
        "  data_dir=opt.dataset_dir, mode=opt.mode, image_size=opt.imageSize, transform=ImgTransform,\n",
        "  episode_num=opt.episode_train_num, way_num=opt.way_num, shot_num=opt.shot_num, query_num=opt.query_num\n",
        ")\n",
        "valset = Imagefolder_csv(\n",
        "  data_dir=opt.dataset_dir, mode='val', image_size=opt.imageSize, transform=ImgTransform,\n",
        "  episode_num=opt.episode_val_num, way_num=opt.way_num, shot_num=opt.shot_num, query_num=opt.query_num\n",
        ")\n",
        "testset = Imagefolder_csv(\n",
        "  data_dir=opt.dataset_dir, mode='test', image_size=opt.imageSize, transform=ImgTransform,\n",
        "  episode_num=opt.episode_test_num, way_num=opt.way_num, shot_num=opt.shot_num, query_num=opt.query_num\n",
        ")\n",
        "\n",
        "print('Trainset: %d' %len(trainset))\n",
        "print('Valset: %d' %len(valset))\n",
        "print('Testset: %d' %len(testset))\n",
        "print('Trainset: %d' %len(trainset), file=F_txt)\n",
        "print('Valset: %d' %len(valset), file=F_txt)\n",
        "print('Testset: %d' %len(testset), file=F_txt)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainset: 10000\n",
            "Valset: 1000\n",
            "Testset: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e32MoDBuKLRQ",
        "outputId": "7cefa0b2-27bc-4d2f-a287-5b8561fd96c3"
      },
      "source": [
        "# ========================================== Load Datasets =========================================\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "  trainset, batch_size=opt.episodeSize, shuffle=True, \n",
        "  num_workers=int(opt.workers), drop_last=True, pin_memory=True\n",
        "  )\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "  valset, batch_size=opt.testepisodeSize, shuffle=True, \n",
        "  num_workers=int(opt.workers), drop_last=True, pin_memory=True\n",
        "  ) \n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "  testset, batch_size=opt.testepisodeSize, shuffle=True, \n",
        "  num_workers=int(opt.workers), drop_last=True, pin_memory=True\n",
        "  ) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs9vyff6bdZl",
        "outputId": "b8a6e2ce-712f-4d2c-edc3-955c79d3674c"
      },
      "source": [
        "batch_time = AverageMeter()\n",
        "data_time = AverageMeter()\n",
        "losses = AverageMeter()\n",
        "top1 = AverageMeter()\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "for episode_index, (query_images, query_targets, support_images, support_targets) in enumerate(train_loader):\n",
        "\n",
        "  # Measure data loading time\n",
        "  data_time.update(time.time() - end)\n",
        "\n",
        "  # Convert query and support images\n",
        "  query_images = torch.cat(query_images, 0)\n",
        "  input_var1 = query_images.cuda()\n",
        "\n",
        "  input_var2 = []\n",
        "  for i in range(len(support_images)):\n",
        "    temp_support = support_images[i]\n",
        "    temp_support = torch.cat(temp_support, 0)\n",
        "    temp_support = temp_support.cuda()\n",
        "    input_var2.append(temp_support)\n",
        "\n",
        "  # Deal with the targets\n",
        "  target = torch.cat(query_targets, 0)\n",
        "  target = target.cuda()\n",
        "\n",
        "  # Calculate the output\n",
        "  output = model(input_var1, input_var2)\n",
        "  loss = criterion(output, target)\n",
        "\n",
        "  # Compute gradients and do SGD step\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  \n",
        "  # Measure accuracy and record loss\n",
        "  prec1, _ = accuracy(output, target, topk=(1,3))\n",
        "  losses.update(loss.item(), query_images.size(0))\n",
        "  top1.update(prec1[0], query_images.size(0))\n",
        "\n",
        "\n",
        "  # Measure elapsed time\n",
        "  batch_time.update(time.time() - end)\n",
        "  end = time.time()\n",
        "  break;\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbRRUomzcEVW",
        "outputId": "764336cf-743a-457f-9cd7-7c2e96de52ca"
      },
      "source": [
        "print(input_var2[0].size())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 84, 84])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YioKzdxccVs",
        "outputId": "1f0153f6-a9c7-4472-9196-abb702277a4d"
      },
      "source": [
        "print(target.size())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3icXtW57c3rX",
        "outputId": "19764f3c-2b89-42a4-abb4-916848562253"
      },
      "source": [
        "print(input_var1.size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 3, 84, 84])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgB7isqZCMrb",
        "outputId": "3cbf9b9a-af36-4781-c778-0b5535299884"
      },
      "source": [
        "print(target)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
            "        4, 4], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}